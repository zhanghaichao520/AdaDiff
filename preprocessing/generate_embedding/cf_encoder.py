# preprocessing/generate_embeddings/cf_encoder.py

import os
import sys
import json
import time
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm

# =================================================================
# 1. å¯¼å…¥çˆ¶ç›®å½•å…±äº«å‡½æ•° (utils.py)
# =================================================================
try:
    # å°†çˆ¶ç›®å½• (preprocessing/) æ·»åŠ åˆ° Python è·¯å¾„
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ utils.py åœ¨ preprocessing/ ç›®å½•æˆ–å…¶çˆ¶çº§ç›®å½•
    # å¦‚æœ utils.py åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œå¯èƒ½éœ€è¦å†å¾€ä¸Šä¸€å±‚
    # è¿™é‡Œå°è¯•é€‚é…å¸¸è§çš„ç»“æ„ï¼š
    # root/
    #   preprocessing/
    #     generate_embeddings/
    #       cf_encoder.py
    #   utils.py
    
    # å°è¯•ä»ä¸Šä¸¤çº§å¯¼å…¥ (å¦‚æœ utils åœ¨ root ä¸‹)
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    
    from utils import load_json, set_device
    print("[INFO] cf_encoder: æˆåŠŸå¯¼å…¥ utils æ¨¡å—ã€‚")
except ImportError:
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå®šä¹‰ç®€å•çš„æ›¿ä»£å‡½æ•°ä»¥é˜²æŠ¥é”™ (ä»…ä½œå¤‡ç”¨)
    print("[WARN] æ— æ³•å¯¼å…¥ utils.pyï¼Œä½¿ç”¨æœ¬åœ°å›é€€å‡½æ•°ã€‚")
    def set_device(gpu_id):
        return torch.device(f"cuda:{gpu_id}" if torch.cuda.is_available() and gpu_id >= 0 else "cpu")

# =================================================================
# 2. SASRec æ•°æ®é›†
# =================================================================

class SASRecDataset(Dataset):
    def __init__(self, data_path, max_seq_len): 
        self.data_path = data_path
        self.max_seq_len = max_seq_len
        self.lines = []
        try:
            with open(data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        self.lines.append(line.strip())
        except FileNotFoundError:
             print(f"é”™è¯¯ï¼šSASRec æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}")
             raise
        except Exception as e:
             print(f"é”™è¯¯ï¼šè¯»å–æ–‡ä»¶å¤±è´¥: {e}")
             raise

    def __len__(self):
        return len(self.lines)

    def __getitem__(self, idx):
        try:
            line = self.lines[idx]
            data = json.loads(line)
            # å‡è®¾æ•°æ®ä¸­çš„ ID æ˜¯ä» 0 å¼€å§‹çš„ï¼Œæ¨¡å‹ä¸­ reserved 0 ä½œä¸º padding
            # æ‰€ä»¥è¾“å…¥ ID + 1
            history_ids = [int(i) + 1 for i in data["history"]] 
            target_id = int(data["target"]) + 1 
            
            seq = history_ids[-self.max_seq_len:]
            seq_len = len(seq)
            padding_len = self.max_seq_len - seq_len
            
            # å·¦å¡«å……è¿˜æ˜¯å³å¡«å……ï¼ŸSASRecé€šå¸¸æ˜¯å·¦ä¾§æ˜¯å†å²ï¼Œå¦‚æœé•¿åº¦ä¸å¤Ÿï¼Œ
            # ä¸ºäº†æ–¹ä¾¿å¤„ç†ï¼Œé€šå¸¸æŠŠæœ‰æ•ˆæ•°æ®æ”¾åœ¨æœ€åï¼Œå‰é¢è¡¥0ï¼Œæˆ–è€…åé¢è¡¥0é…åˆmask
            # è¿™é‡Œé‡‡ç”¨ï¼š[æœ‰æ•ˆåºåˆ—, 0, 0] (å³å¡«å……) å¹¶é…åˆ seq_len ä½¿ç”¨
            seq = seq + [0] * padding_len
            
            return torch.tensor(seq, dtype=torch.long), \
                   torch.tensor(target_id, dtype=torch.long), \
                   torch.tensor(seq_len, dtype=torch.long)
        except Exception as e:
             print(f"è­¦å‘Šï¼šæ•°æ®è§£æé”™è¯¯ (è¡Œ {idx}): {e}")
             return torch.zeros(self.max_seq_len, dtype=torch.long), \
                    torch.tensor(0, dtype=torch.long), \
                    torch.tensor(0, dtype=torch.long)

# =================================================================
# 3. SASRec æ¨¡å‹
# =================================================================

class SASRecModel(nn.Module):
    def __init__(self, n_items, hidden_dim, max_seq_len, n_layers, n_heads, dropout=0.1):
        super(SASRecModel, self).__init__()
        self.n_items = n_items
        self.hidden_dim = hidden_dim
        
        # padding_idx=0, æ‰€ä»¥ embedding size æ˜¯ n_items + 1
        self.item_embedding = nn.Embedding(self.n_items + 1, hidden_dim, padding_idx=0)
        self.position_embedding = nn.Embedding(max_seq_len, hidden_dim)
        self.emb_dropout = nn.Dropout(dropout)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim, nhead=n_heads, dim_feedforward=hidden_dim * 4,
            dropout=dropout, batch_first=True, activation='gelu', norm_first=True
        )
        encoder_norm = nn.LayerNorm(hidden_dim)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers, norm=encoder_norm)
        self.layer_norm = nn.LayerNorm(hidden_dim)

        # åˆå§‹åŒ–æƒé‡ (Xavier initialization usually good for Transformers)
        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)
        if isinstance(module, nn.Linear) and module.bias is not None:
            module.bias.data.zero_()

    def forward(self, item_seq, seq_lengths):
        # seq_lengths: [batch_size]
        # item_seq: [batch_size, max_len]
        
        # è¾¹ç•Œæ£€æŸ¥
        seq_lengths = torch.clamp(seq_lengths, min=1)
        
        # ç”Ÿæˆ Mask: True è¡¨ç¤ºæ˜¯ padding (ä¸éœ€è¦å…³æ³¨çš„ä½ç½®)
        # item_seq == 0 çš„ä½ç½®æ˜¯ padding
        padding_mask = (item_seq == 0)

        item_emb = self.item_embedding(item_seq)
        
        # Positional Embedding
        pos_ids = torch.arange(item_seq.size(1), device=item_seq.device).unsqueeze(0)
        pos_emb = self.position_embedding(pos_ids)
        
        x = self.emb_dropout(item_emb + pos_emb)
        
        # Transformer Encoder
        # src_key_padding_mask: [batch, seq_len] (True for padding)
        transformer_out = self.transformer_encoder(x, src_key_padding_mask=padding_mask)
        transformer_out = self.layer_norm(transformer_out) 
        
        # å–åºåˆ—ä¸­æœ€åä¸€ä¸ªæœ‰æ•ˆ item çš„ embedding ä½œä¸º User Embedding
        # gather indices: [batch, 1, hidden]
        batch_indices = torch.arange(transformer_out.size(0), device=transformer_out.device)
        last_item_indices = seq_lengths - 1
        
        user_emb = transformer_out[batch_indices, last_item_indices, :] # [batch, hidden]
        
        # è®¡ç®— Logits (é¢„æµ‹ä¸‹ä¸€ä¸ª item)
        # item_embedding.weight: [n_items+1, hidden]
        # æˆ‘ä»¬é€šå¸¸å¸Œæœ›è®¡ç®—æ‰€æœ‰ç‰©å“çš„å¾—åˆ†
        logits = user_emb @ self.item_embedding.weight.T # [batch, n_items+1]
        
        return logits

# =================================================================
# 4. è¾…åŠ©å·¥å…·ï¼šEarlyStopping å’Œ Metrics
# =================================================================

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    def __init__(self, patience=5, verbose=False, delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = -np.inf # å‡è®¾æŒ‡æ ‡è¶Šå¤§è¶Šå¥½ (å¦‚ NDCG)
        self.early_stop = False
        self.best_model_state = None
        self.delta = delta

    def __call__(self, score, model):
        if score > self.best_score + self.delta:
            self.best_score = score
            self.save_checkpoint(score, model)
            self.counter = 0
        else:
            self.counter += 1
            if self.verbose:
                print(f'   [EarlyStop] Counter: {self.counter} / {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True

    def save_checkpoint(self, score, model):
        if self.verbose:
            print(f'   [EarlyStop] Metric improved to {score:.6f}. Caching model...')
        # ä¿å­˜å‚æ•°åˆ° CPU å†…å­˜ï¼Œé¿å…å ç”¨æ˜¾å­˜
        self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}

def calculate_metrics(logits, target, k_list=[10, 20]):
    """è®¡ç®— Recall@K å’Œ NDCG@K"""
    # logits: [batch, n_items+1]
    # target: [batch]
    
    # ç§»é™¤ padding (index 0) çš„å½±å“ï¼Œå°† logit[0] è®¾ä¸ºè´Ÿæ— ç©·
    logits[:, 0] = -float('inf')
    
    batch_size = logits.size(0)
    max_k = max(k_list)
    
    # è·å– TopK ç´¢å¼•
    _, topk_indices = torch.topk(logits, max_k, dim=-1) # [batch, max_k]
    
    target = target.view(-1, 1) # [batch, 1]
    hit = (topk_indices == target) # [batch, max_k]
    
    metrics = {}
    for k in k_list:
        hit_k = hit[:, :k]
        num_hit = hit_k.sum().item()
        
        # Recall
        metrics[f'Recall@{k}'] = num_hit / batch_size
        
        # NDCG
        hit_positions = hit_k.nonzero(as_tuple=False)[:, 1] # rank (0-based)
        if len(hit_positions) > 0:
            # log2(rank + 2) because rank is 0-based
            dcg = 1.0 / torch.log2(hit_positions.float() + 2.0)
            metrics[f'NDCG@{k}'] = dcg.sum().item() / batch_size
        else:
            metrics[f'NDCG@{k}'] = 0.0
            
    return metrics

def evaluate(model, dataloader, device, k_list=[10, 20]):
    model.eval()
    total_metrics = {f'Recall@{k}': 0.0 for k in k_list}
    total_metrics.update({f'NDCG@{k}': 0.0 for k in k_list})
    n_batches = 0
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating", leave=False):
            seq, target, seq_len = [b.to(device) for b in batch]
            
            # è¿‡æ»¤æ— æ•ˆ batch
            valid = seq_len > 0
            if not valid.any(): continue
            seq = seq[valid]
            target = target[valid]
            seq_len = seq_len[valid]
            
            logits = model(seq, seq_len)
            batch_metrics = calculate_metrics(logits, target, k_list)
            
            for k, v in batch_metrics.items():
                total_metrics[k] += v
            n_batches += 1
            
    if n_batches > 0:
        for k in total_metrics:
            total_metrics[k] /= n_batches
            
    return total_metrics

# =================================================================
# 5. ä¸»æµç¨‹å‡½æ•°
# =================================================================

def train_and_extract_sasrec(args, n_items: int) -> np.ndarray:
    """
    è®­ç»ƒ SASRec æ¨¡å‹å¹¶æå–ç‰©å“åµŒå…¥ã€‚
    """
    print(f"\nğŸ”¹ [SASRec] å¼€å§‹è®­ç»ƒååŒè¿‡æ»¤æ¨¡å‹ (Target Items: {n_items})...")
    device = args.device

    # --- 1. è·¯å¾„è®¾ç½® ---
    data_dir = os.path.join(args.save_root, args.dataset) 
    train_path = os.path.join(data_dir, f"{args.dataset}.train.jsonl")
    valid_path = os.path.join(data_dir, f"{args.dataset}.valid.jsonl")
    
    if not os.path.exists(train_path):
        raise FileNotFoundError(f"é”™è¯¯: æ‰¾ä¸åˆ° SASRec è®­ç»ƒæ–‡ä»¶ {train_path}")

    has_valid = os.path.exists(valid_path)
    if not has_valid:
        print("âš ï¸ [è­¦å‘Š] æœªæ‰¾åˆ°éªŒè¯é›† (.valid.jsonl)ã€‚Early Stopping å°†è¢«ç¦ç”¨ï¼Œä»…æŒ‰ Epochs è®­ç»ƒã€‚")

    # --- 2. DataLoader ---
    num_workers = getattr(args, 'num_workers', 4)
    print(f"Loading data (Workers: {num_workers})...")
    
    train_dataset = SASRecDataset(train_path, args.sasrec_max_seq_len) 
    train_loader = DataLoader(
        train_dataset, batch_size=args.batch_size, 
        shuffle=True, num_workers=num_workers, pin_memory=True
    )
    
    valid_loader = None
    if has_valid:
        valid_dataset = SASRecDataset(valid_path, args.sasrec_max_seq_len)
        # éªŒè¯æ—¶ Batch å¯ä»¥ç¨å¾®å¤§ä¸€ç‚¹ï¼Œå› ä¸ºä¸éœ€è¦åå‘ä¼ æ’­
        valid_loader = DataLoader(
            valid_dataset, batch_size=args.batch_size, 
            shuffle=False, num_workers=num_workers, pin_memory=True
        )

    # --- 3. æ¨¡å‹æ„å»º ---
    model = SASRecModel(
        n_items=n_items,
        hidden_dim=args.sasrec_hidden_dim,
        max_seq_len=args.sasrec_max_seq_len,
        n_layers=args.sasrec_n_layers,
        n_heads=args.sasrec_n_heads,
        dropout=args.sasrec_dropout
    ).to(device)
    
    criterion = nn.CrossEntropyLoss(ignore_index=0)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.sasrec_lr, weight_decay=args.sasrec_weight_decay)
    
    # Early Stopping è®¾ç½®
    patience = getattr(args, 'patience', 5)
    early_stopping = EarlyStopping(patience=patience, verbose=True)
    
    # --- 4. è®­ç»ƒå¾ªç¯ ---
    print(f"å¼€å§‹è®­ç»ƒ (Epochs: {args.sasrec_epochs}, Patience: {patience})...")
    start_time = time.time()
    
    for epoch in range(1, args.sasrec_epochs + 1):
        # Train
        model.train()
        total_loss = 0
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{args.sasrec_epochs} [Train]", leave=False)
        
        for batch in train_pbar:
            seq, target, seq_len = [b.to(device) for b in batch]
            
            valid_mask = (seq_len > 0)
            if not valid_mask.any(): continue
            seq = seq[valid_mask]
            target = target[valid_mask]
            seq_len = seq_len[valid_mask]

            optimizer.zero_grad()
            logits = model(seq, seq_len)
            loss = criterion(logits, target)
            
            if torch.isnan(loss):
                continue
                
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            train_pbar.set_postfix({"Loss": f"{loss.item():.4f}"})
            
        avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0
        
        # Valid
        log_msg = f"Epoch {epoch} | Loss: {avg_loss:.4f}"
        
        if has_valid:
            val_metrics = evaluate(model, valid_loader, device)
            metric_str = " | ".join([f"{k}: {v:.4f}" for k, v in val_metrics.items()])
            log_msg += f" | {metric_str}"
            print(log_msg)
            
            # ä½¿ç”¨ NDCG@10 ä½œä¸º Early Stop çš„ä¸»è¦æŒ‡æ ‡
            monitor_score = val_metrics.get('NDCG@10', 0)
            early_stopping(monitor_score, model)
            
            if early_stopping.early_stop:
                print(f"ğŸ›‘ Early stopping triggered at Epoch {epoch}!")
                break
        else:
            print(log_msg)
            # å¦‚æœæ²¡æœ‰éªŒè¯é›†ï¼Œæˆ‘ä»¬ä¹Ÿä¿å­˜å½“å‰æ¨¡å‹ä¸ºâ€œæœ€ä½³â€
            early_stopping.best_model_state = model.state_dict()

    train_duration = time.time() - start_time
    print(f"SASRec è®­ç»ƒå®Œæˆ. è€—æ—¶: {train_duration:.2f}s")

    # --- 5. æ¢å¤æœ€ä½³æ¨¡å‹å¹¶æå– Embedding ---
    if has_valid and early_stopping.best_model_state is not None:
        print("æ­£åœ¨æ¢å¤éªŒè¯é›†è¡¨ç°æœ€ä½³çš„æ¨¡å‹å‚æ•°...")
        model.load_state_dict(early_stopping.best_model_state)
    
    print("æ­£åœ¨æå–ç‰©å“åµŒå…¥ (Item Embeddings)...")
    model.eval()
    try:
        with torch.no_grad():
            # è·å– embedding weight: [n_items + 1, hidden_dim]
            all_embeddings = model.item_embedding.weight.data.cpu().numpy()
        
        # å»é™¤ index 0 (padding)
        # æˆ‘ä»¬çš„ item ID æ˜¯ 1~Nï¼Œå¯¹åº” embedding ç´¢å¼• 1~N
        # ç»“æœéœ€è¦æ˜¯ [n_items, hidden_dim]
        embeddings = all_embeddings[1:] 
        
        print(f"åŸå§‹ Embedding å½¢çŠ¶: {embeddings.shape}")
        
        # ç»´åº¦æ ¡éªŒä¸ä¿®å¤
        if embeddings.shape[0] != n_items:
            print(f"[è­¦å‘Š] åµŒå…¥æ•°é‡ ({embeddings.shape[0]}) ä¸ n_items ({n_items}) ä¸ä¸€è‡´ã€‚")
            if embeddings.shape[0] < n_items:
                print(" -> å¡«å……é›¶å‘é‡...")
                pad = np.zeros((n_items - embeddings.shape[0], embeddings.shape[1]), dtype=embeddings.dtype)
                embeddings = np.concatenate([embeddings, pad], axis=0)
            else:
                print(" -> æˆªæ–­...")
                embeddings = embeddings[:n_items]
                
        return embeddings.astype(np.float32)

    except Exception as e:
        print(f"æå–åµŒå…¥å¤±è´¥: {e}")
        raise