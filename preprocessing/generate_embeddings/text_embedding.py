import argparse
import os
import random
import torch
import numpy as np
from tqdm import tqdm
from sklearn.decomposition import PCA
from transformers import AutoTokenizer, AutoModel
import sys, os
import time

# å‡è®¾ utils.py åœ¨ä¸Šä¸€çº§ç›®å½•
try:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils import load_json, clean_text, set_device
except ImportError:
    print("é”™è¯¯: æ‰¾ä¸åˆ° utils.pyã€‚è¯·ç¡®ä¿å®ƒåœ¨ä¸Šä¸€çº§ç›®å½•æˆ– Python è·¯å¾„ä¸­ã€‚")
    sys.exit(1)


# =============== (å…±äº«) æ•°æ®é¢„å¤„ç† ===============
def load_data(args):
    """(å…±äº«) åŠ è½½ .item.json æ–‡ä»¶"""
    item2feature_path = os.path.join(args.root, f'{args.dataset}.item.json')
    return load_json(item2feature_path)


def generate_text(item2feature, features):
    """(å…±äº«) ä»æŒ‡å®šçš„ç‰¹å¾åˆ—è¡¨ä¸­æ‹¼æ¥æ–‡æœ¬"""
    item_text_list = []
    for item, data in item2feature.items():
        text = []
        for meta_key in features:
            if meta_key in data:
                meta_value = data[meta_key]
                if isinstance(meta_value, list):
                    meta_value = " ".join(meta_value)
                
                meta_value = clean_text(meta_value)
                if meta_value.strip():
                    text.append(meta_value.strip())
        
        item_text_list.append([int(item), text])
    return item_text_list


def preprocess_text(args):
    """
    (è°ƒåº¦å™¨) æ ¹æ® dataset_type é€‰æ‹©è¦æå–çš„æ–‡æœ¬ç‰¹å¾
    """
    print(f"å¤„ç†æ–‡æœ¬æ•°æ®: {args.dataset} (ç±»å‹: {args.dataset_type})")
    item2feature = load_data(args)
    
    features = []
    if args.dataset_type == 'movielens':
        features = ['title', 'description', 'genres']
    elif args.dataset_type == 'amazon':
        features = ['title', 'description', 'brand', 'categories']
    else:
        raise ValueError(f"æœªçŸ¥çš„ dataset_type: {args.dataset_type}")
        
    print(f"å°†ä½¿ç”¨ä»¥ä¸‹å…ƒæ•°æ®å­—æ®µ: {features}")
    return generate_text(item2feature, features)


# =============== (å…±äº«) æœ¬åœ°æ¨¡å‹åµŒå…¥ç”Ÿæˆ ===============
def generate_local_embeddings(args, item_text_list):
    print(f"ğŸ”¹ ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”ŸæˆåµŒå…¥: {args.model_name_or_path}")
    from transformers import AutoTokenizer, AutoModel
    
    # è‡ªåŠ¨ä¿¡ä»»è¿œç¨‹ä»£ç ï¼ˆé€‚ç”¨äº Qwen ç­‰æ¨¡å‹ï¼‰
    tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, trust_remote_code=True)
    model = AutoModel.from_pretrained(args.model_name_or_path, trust_remote_code=True).to(args.device)
    model.eval()

    items, texts = zip(*item_text_list)
    order_texts = [[0]] * len(items)
    for item, text in zip(items, texts):
        order_texts[item] = text
    for i, text in enumerate(order_texts):
        if text == [0]:
            print(f"[è­¦å‘Š] Item {i} ç¼ºå°‘æ–‡æœ¬æ•°æ®ï¼Œå°†ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ã€‚")
            order_texts[i] = [""] 

    embeddings = []
    start = 0
    with torch.no_grad():
        pbar = tqdm(total=len(order_texts), desc="ç”ŸæˆåµŒå…¥", ncols=100)
        while start < len(order_texts):
            batch_texts = order_texts[start: start + args.batch_size]
            batch_texts = [" ".join(t) if t else "" for t in batch_texts]

            encoded = tokenizer(batch_texts, padding=True, truncation=True,
                                return_tensors="pt", max_length=args.max_sent_len).to(args.device)
            outputs = model(**encoded)
            
            attn = encoded['attention_mask'].unsqueeze(-1)
            masked = outputs.last_hidden_state * attn
            mean_output = masked.sum(dim=1) / attn.sum(dim=1)
            
            embeddings.append(mean_output.cpu())
            start += args.batch_size
            pbar.update(mean_output.size(0))
        pbar.close()

    embeddings = torch.cat(embeddings, dim=0).numpy()
    return embeddings


# =============== (å…±äº«) API æ¨¡å‹åµŒå…¥ç”Ÿæˆ ===============
def generate_api_embeddings(args, item_text_list):
    print(f"ğŸ”¹ ä½¿ç”¨ API æ¨¡å‹ç”ŸæˆåµŒå…¥: {args.sent_emb_model}")
    try:
        from openai import OpenAI
    except ImportError:
        print("é”™è¯¯: 'openai' åº“æœªæ‰¾åˆ°ã€‚è¯·è¿è¡Œ: pip install openai")
        sys.exit(1)
        
    client = OpenAI(api_key=args.openai_api_key, base_url=args.openai_base_url)

    items, texts = zip(*item_text_list)
    order_texts = [[""]] * len(items)
    for item, text in zip(items, texts):
        order_texts[item] = text if text else [""]

    final_texts = [" ".join(t) for t in order_texts]

    sent_embs = []
    for i in tqdm(range(0, len(final_texts), args.batch_size), desc="API Encoding"):
        batch = final_texts[i: i + args.batch_size]
        batch = [t if t.strip() else "N/A" for t in batch]
        
        try:
            response = client.embeddings.create(
                model=args.sent_emb_model,
                input=batch
            )
            sent_embs.extend([d.embedding for d in response.data])
        except Exception as e:
            print(f"[è­¦å‘Š] ç¬¬ {i} æ‰¹è¯·æ±‚å¤±è´¥ (items {i*args.batch_size} - {(i+1)*args.batch_size})ï¼Œé”™è¯¯ï¼š{e}")
            # ç¡®å®š API ç»´åº¦ (ä»å‚æ•°è¯»å–ï¼Œå¦‚æœæœªè®¾ç½®åˆ™å°è¯•ä»ç¬¬ä¸€ä¸ªæˆåŠŸçš„ batch æ¨æ–­)
            api_emb_dim = args.api_emb_dim
            if api_emb_dim <= 0 and len(sent_embs) > 0:
                 api_emb_dim = len(sent_embs[0])
            if api_emb_dim <= 0:
                 print("é”™è¯¯ï¼šAPI ç»´åº¦æœªçŸ¥ä¸”æœªåœ¨ --api_emb_dim ä¸­æŒ‡å®šã€‚æ— æ³•åˆ›å»ºé›¶å‘é‡ã€‚")
                 api_emb_dim = 3072 # é»˜è®¤å›é€€
                 
            sent_embs.extend([np.zeros(api_emb_dim, dtype=np.float32) for _ in batch])
            time.sleep(1)

    sent_embs = np.array(sent_embs, dtype=np.float32)
    
    # åŠ¨æ€è®¾ç½® api_emb_dim (å¦‚æœä¹‹å‰ä¸çŸ¥é“)
    if args.api_emb_dim <= 0 and sent_embs.shape[0] > 0:
        args.api_emb_dim = sent_embs.shape[1]
        
    print(f"API åµŒå…¥ç»´åº¦: {sent_embs.shape}")
    return sent_embs


# =============== (å…±äº«) PCA é™ç»´ (æ¢å¤ä½ åŸæ¥çš„é€»è¾‘) ===============
def apply_pca_and_save(original_embeddings, args, save_path):
    """
    åº”ç”¨ PCA å¹¶ *è¦†ç›–* ä¿å­˜åˆ°åŸå§‹è·¯å¾„ (save_path)ã€‚
    """
    if args.pca_dim <= 0:
        print("è·³è¿‡ PCA é™ç»´ã€‚")
        return

    print(f"\nåº”ç”¨ PCA é™ç»´ï¼Œç›®æ ‡ç»´åº¦: {args.pca_dim}")
    if original_embeddings.shape[1] < args.pca_dim:
        print(f"åŸå§‹ç»´åº¦ ({original_embeddings.shape[1]}) å°äºç›®æ ‡ç»´åº¦ ({args.pca_dim})ï¼Œè·³è¿‡é™ç»´ã€‚")
        return

    pca = PCA(n_components=args.pca_dim)
    reduced = pca.fit_transform(original_embeddings)
    print(f"é™ç»´åç»´åº¦: {reduced.shape}ï¼Œä¿ç•™æ–¹å·®: {sum(pca.explained_variance_ratio_):.4f}")

    np.save(save_path, reduced) # <--- è¦†ç›–åŸå§‹æ–‡ä»¶
    print(f"âœ… PCA é™ç»´ååµŒå…¥å·²ä¿å­˜åˆ°: {save_path}")


# =============== (ç»Ÿä¸€) ä¸»ç¨‹åºå…¥å£ ===============
def parse_args():
    parser = argparse.ArgumentParser(description="ä» .item.json ä¸º Amazon æˆ– MovieLens ç”Ÿæˆæ–‡æœ¬åµŒå…¥")
    
    # --- è°ƒåº¦å‚æ•° (å¿…éœ€) ---
    parser.add_argument('--dataset_type', type=str, required=True, choices=['amazon', 'movielens'],
                        help='è¦å¤„ç†çš„æ•°æ®é›†ç±»å‹ (amazon æˆ– movielens)')
    parser.add_argument('--dataset', type=str, required=True, 
                        help='æ•°æ®é›†åç§° (e.g., Home, Baby, ml-1m, ml-20m)')
    
    # --- é€šç”¨å‚æ•° (ä¿ç•™äº†ä½ çš„æ‰€æœ‰å‚æ•°) ---
    parser.add_argument('--root', type=str, default="../datasets")
    parser.add_argument('--gpu_id', type=int, default=0)
    parser.add_argument('--batch_size', type=int, default=512)
    parser.add_argument('--max_sent_len', type=int, default=1024)
    parser.add_argument('--pca_dim', type=int, default=512, 
                        help="PCA é™ç»´çš„ç›®æ ‡ç»´åº¦ã€‚<= 0 è¡¨ç¤ºä¸è¿›è¡Œ PCAã€‚")
    parser.add_argument('--mode', type=str, choices=['local', 'api'], default='local',
                        help="ä½¿ç”¨ 'local' (transformers) è¿˜æ˜¯ 'api' (OpenAI)")

    # --- æœ¬åœ°æ¨¡å‹å‚æ•° ---
    parser.add_argument('--model_name_or_path', type=str, default='sentence-transformers/sentence-t5-base')

    # --- API å‚æ•° ---
    parser.add_argument('--sent_emb_model', type=str, default='text-embedding-3-large',
                        help="OpenAI æ¨¡å‹ (e.g., text-embedding-3-large, text-embedding-3-small)")
    parser.add_argument('--api_emb_dim', type=int, default=0,
                        help="API æ¨¡å‹çš„ç»´åº¦ (3-large=3072, 3-small=1536)ã€‚å¦‚æœä¸º0ï¼Œå°†è‡ªåŠ¨æ£€æµ‹ï¼Œä½†åœ¨APIè¯·æ±‚å¤±è´¥æ—¶å¯èƒ½å‡ºé”™ã€‚")
    parser.add_argument('--openai_api_key', type=str, default=os.environ.get('OPENAI_API_KEY', 'sk-xxx'),
                        help="OpenAI API å¯†é’¥ã€‚é»˜è®¤ä»ç¯å¢ƒå˜é‡ OPENAI_API_KEY è¯»å–ã€‚")
    parser.add_argument('--openai_base_url', type=str, default=os.environ.get('OPENAI_BASE_URL', 'https://api.openai.com/v1'),
                        help="OpenAI API Base URLã€‚é»˜è®¤ä»ç¯å¢ƒå˜é‡ OPENAI_BASE_URL è¯»å–ã€‚")

    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    
    # è·¯å¾„è®¾ç½®
    args.root = os.path.join(args.root, args.dataset)
    os.makedirs(args.root, exist_ok=True)
    args.device = set_device(args.gpu_id)

    # 1. é¢„å¤„ç† (æ ¹æ® dataset_type è°ƒåº¦)
    item_text_list = preprocess_text(args)
    
    # åŠ¨æ€è®¾ç½® API ç»´åº¦ (é’ˆå¯¹ text-embedding-3-large)
    if args.mode == 'api' and args.sent_emb_model == 'text-embedding-3-large' and args.api_emb_dim == 0:
        args.api_emb_dim = 3072
    if args.mode == 'api' and args.sent_emb_model == 'text-embedding-3-small' and args.api_emb_dim == 0:
        args.api_emb_dim = 1536

    # 2. ç”ŸæˆåµŒå…¥ (æ ¹æ® mode è°ƒåº¦)
    emb = None
    if args.mode == "local":
        emb = generate_local_embeddings(args, item_text_list)
    elif args.mode == "api":
        emb = generate_api_embeddings(args, item_text_list)
    else:
        raise ValueError("æœªçŸ¥æ¨¡å¼ï¼Œè¯·é€‰æ‹© local æˆ– api")

    # --- 3. ä¿å­˜ (æ¢å¤ä½ åŸæ¥çš„é€»è¾‘) ---
    
    # åˆ›å»ºç‹¬ç«‹ embedding ç›®å½•
    emb_dir = os.path.join(args.root, "embeddings")
    os.makedirs(emb_dir, exist_ok=True)

    # å®šä¹‰æ¨¡å‹æ ‡è¯†
    model_tag = args.model_name_or_path.split('/')[-1] if args.mode == "local" else args.sent_emb_model
    model_tag = model_tag.replace('/', '-') # ç§»é™¤è·¯å¾„æ–œæ 

    # 3a. å®šä¹‰ *æœ€ç»ˆ* è·¯å¾„
    save_path = os.path.join(emb_dir, f"{args.dataset}.emb-text-{model_tag}.npy")
    
    # 3b. ä¿å­˜å®Œæ•´åµŒå…¥
    np.save(save_path, emb)
    print(f"âœ… æ–‡æœ¬åµŒå…¥å·²ä¿å­˜è‡³: {save_path} (ç»´åº¦: {emb.shape})")

    # 3c. (å¯é€‰) ä½¿ç”¨ PCA è¦†ç›–
    if args.pca_dim > 0:
        # è°ƒç”¨å‡½æ•°ï¼Œä¼ å…¥ *ç›¸åŒ* çš„ save_path æ¥å®ç°è¦†ç›–
        apply_pca_and_save(emb, args, save_path)
    else:
        print("pca_dim <= 0ï¼Œè·³è¿‡ PCA é™ç»´ã€‚")
        
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚")