import os
import json
import argparse
from tqdm import tqdm
from typing import Dict, Any, Tuple, List
import random

# å‡è®¾ load_json æ˜¯ä¸€ä¸ªå¯ä»¥å¤„ç† JSON æ–‡ä»¶çš„å…±äº«å‡½æ•° 
def load_json(p):
    try:
        with open(p, "r") as f:
            return json.load(f)
    except Exception as e:
        return None

def verify_alignment(args):
    """ä¸»å¯¹é½æ£€æŸ¥å‡½æ•°"""
    print("=" * 60)
    print(f"ğŸ”¹ å¯åŠ¨å¯¹é½éªŒè¯ ({args.dataset})")
    print("=" * 60)

    # --- 1. æ–‡ä»¶è·¯å¾„è®¾ç½® ---
    dataset_path = os.path.join(args.data_root, args.dataset)
    
    # æ ¸å¿ƒæ˜ å°„æ–‡ä»¶ (ç”± preprocess_data.py ç”Ÿæˆ)
    item2id_path = os.path.join(dataset_path, f"{args.dataset}.item2id")
    item_meta_path = os.path.join(dataset_path, f"{args.dataset}.item.json")
    
    # å›¾åƒä¿¡æ¯æ–‡ä»¶ (ç”± download_images.py ç”Ÿæˆ)
    images_info_path = os.path.join(args.image_info_root, f"{args.dataset}_images_info.json")
    
    # âœ… ä¿®æ­£è·¯å¾„ï¼šå›¾åƒæ–‡ä»¶å¤¹åº”è¯¥åœ¨ args.image_root ä¸‹ï¼Œä»¥ args.dataset å‘½å
    # ä¾‹å¦‚ï¼š../datasets/amazon14/Images/Baby/
    image_dir = os.path.join(args.image_root, args.dataset) 

    print(f"æ£€æŸ¥ Item2ID æ–‡ä»¶: {item2id_path}")
    print(f"æ£€æŸ¥ Item Meta æ–‡ä»¶: {item_meta_path}")
    print(f"æ£€æŸ¥ Images Info æ–‡ä»¶: {images_info_path}")
    print(f"æ£€æŸ¥ Image Directory: {image_dir}") # <-- è·¯å¾„ç°åœ¨æ˜¯æ­£ç¡®çš„å•å±‚

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(item2id_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° item2id æ–‡ä»¶ ({item2id_path})ã€‚è¯·å…ˆè¿è¡Œé¢„å¤„ç†ã€‚")
        return
    if not os.path.exists(item_meta_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° item.json æ–‡ä»¶ ({item_meta_path})ã€‚è¯·å…ˆè¿è¡Œé¢„å¤„ç†ã€‚")
        return
    if not os.path.exists(images_info_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° images_info æ–‡ä»¶ ({images_info_path})ã€‚è¯·å…ˆä¸‹è½½å›¾ç‰‡ã€‚")
        return

    # --- 2. åŠ è½½æ ¸å¿ƒæ˜ å°„æ•°æ® ---
    newid_to_origid: Dict[str, str] = {}
    origid_to_newid: Dict[str, str] = {}
    try:
        with open(item2id_path, "r") as f:
            for line in f:
                parts = line.strip().split("\t")
                if len(parts) == 2:
                    orig_id, new_id = parts
                    newid_to_origid[new_id] = orig_id
                    origid_to_newid[orig_id] = new_id
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¯»å– item2id æ–‡ä»¶å¤±è´¥: {e}")
        return
        
    item_meta = load_json(item_meta_path)
    if not isinstance(item_meta, dict):
        print(f"âŒ é”™è¯¯: åŠ è½½ item.json å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")
        return

    images_info = load_json(images_info_path)
    if not isinstance(images_info, dict):
        print(f"âŒ é”™è¯¯: åŠ è½½ images_info å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")
        return

    # --- 3. è·¨æ–‡ä»¶ä¸€è‡´æ€§æ£€æŸ¥ ---
    total_items = len(newid_to_origid)
    print(f"\n[INFO] æ€»å…±æ‰¾åˆ° {total_items} ä¸ªç‰©å“éœ€è¦æ£€æŸ¥ã€‚")
    
    meta_mismatch_count = 0
    img_coverage_count = 0
    img_file_missing_count = 0
    
    check_results: List[Tuple[str, str, str]] = [] # (new_id, title_status, image_status)
    
    for new_id in tqdm(newid_to_origid.keys(), desc="æ‰§è¡Œå¯¹é½æ£€æŸ¥"):
        orig_id = newid_to_origid[new_id]
        
        # æ£€æŸ¥ Item Meta å¯¹é½ (æ–‡æœ¬)
        meta_data = item_meta.get(new_id)
        if not meta_data:
            meta_status = "âŒ META MISSING"
            meta_mismatch_count += 1
        else:
            meta_status = "âœ… META OK"
        
        # æ£€æŸ¥ Image Info å¯¹é½ (å›¾åƒ)
        img_names = images_info.get(orig_id, [])
        img_info_status = "âŒ IMG_INFO MISSING"
        img_file_status = "âŒ FILE MISSING"
        
        if img_names and isinstance(img_names, list) and len(img_names) > 0:
            img_info_status = "âœ… IMG_INFO OK"
            img_coverage_count += 1
            
            # æ£€æŸ¥æ–‡ä»¶ç‰©ç†å­˜åœ¨æ€§ (åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶)
            first_img_path = os.path.join(image_dir, img_names[0])
            if os.path.exists(first_img_path):
                 img_file_status = "âœ… FILE OK"
            else:
                 img_file_status = "âŒ FILE MISSING"
                 img_file_missing_count += 1
        
        check_results.append((new_id, orig_id, meta_data.get('title', 'N/A') if meta_data else 'N/A', img_info_status, img_file_status))

    # --- 4. æ‰“å°ç»“æœ ---
    print("\n" + "=" * 60)
    print("âœ… éªŒè¯ç»“æœæ€»ç»“ï¼š")
    print("-" * 60)
    print(f"æ€»ç‰©å“æ•° (æ¥è‡ª {args.dataset}.item2id): {total_items}")
    print(f"1. æ–‡æœ¬å…ƒæ•°æ® ({args.dataset}.item.json) ç¼ºå¤±æ•°: {meta_mismatch_count}")
    print(f"2. å›¾ç‰‡ä¿¡æ¯ ({os.path.basename(images_info_path)}) è¦†ç›–æ•°: {img_coverage_count}")
    print(f"3. å›¾ç‰‡æ–‡ä»¶ç‰©ç†ä¸¢å¤±æ•° (åœ¨ {image_dir} ä¸­): {img_file_missing_count}")
    
    if meta_mismatch_count > 0:
         print(f"ğŸš¨ **ä¸¥é‡è­¦å‘Š:** æœ‰ {meta_mismatch_count} ä¸ªæ–° ID åœ¨ item.json ä¸­æ‰¾ä¸åˆ°å…ƒæ•°æ®ã€‚è¿™å¯èƒ½æ„å‘³ç€é¢„å¤„ç†æœ‰ BUGï¼Œæˆ–è€… meta/rating æ–‡ä»¶ä¸ä¸€è‡´ã€‚")
    if img_file_missing_count > 0:
         print(f"ğŸš¨ **è­¦å‘Š:** æœ‰ {img_file_missing_count} ä¸ªæ–‡ä»¶åœ¨ images_info ä¸­æœ‰è®°å½•ï¼Œä½†ç‰©ç†æ–‡ä»¶ä¸¢å¤±ã€‚è¯·é‡æ–°è¿è¡Œä¸‹è½½è„šæœ¬ã€‚")
         
    if total_items > 0:
         print(f"å›¾ç‰‡ä¿¡æ¯è¦†ç›–ç‡: {img_coverage_count / total_items:.2%}")
    print("-" * 60)
    
    print("\nğŸš€ éšæœºæŠ½æ ·æ£€æŸ¥ (5ä¸ª Items):")
    for new_id, orig_id, title, img_info_status, img_file_status in random.sample(check_results, min(5, total_items)):
        print(f"  æ–°ID: {new_id} -> åŸå§‹ID: {orig_id}")
        print(f"    - æ ‡é¢˜: {title[:50]}...")
        print(f"    - å›¾ç‰‡ä¿¡æ¯çŠ¶æ€: {img_info_status}")
        print(f"    - å›¾ç‰‡æ–‡ä»¶çŠ¶æ€: {img_file_status}")
    print("=" * 60)


def parse_args():
    parser = argparse.ArgumentParser(description="å¤šæ¨¡æ€æ•°æ®é›†å¯¹é½éªŒè¯å·¥å…·")
    parser.add_argument('--dataset', type=str, required=True, help='æ•°æ®é›†åç§° (e.g., Baby)')
    parser.add_argument('--data_root', type=str, default='../datasets', help='é¢„å¤„ç†æ–‡ä»¶ (.item2id, .item.json) æ‰€åœ¨çš„æ ¹ç›®å½•')
    parser.add_argument('--image_info_root', type=str, default='../datasets/amazon14/Images', 
                        help='åŒ…å« _images_info.json æ–‡ä»¶çš„ç›®å½•ã€‚æ³¨æ„Amazonç‰ˆæœ¬ã€‚')
    parser.add_argument('--image_root', type=str, default='../datasets/amazon14/Images',
                        help='åŒ…å«å®é™…å›¾ç‰‡æ–‡ä»¶çš„æ ¹ç›®å½• (ä¾‹å¦‚ .../Images/)')
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()
    
    # ğŸš¨ ç§»é™¤è¿™ä¸€å—å¯¼è‡´è·¯å¾„é‡å¤çš„é€»è¾‘ï¼
    # if 'Images' in args.image_root:
    #     args.image_root = os.path.join(args.image_root, args.dataset)
    
    verify_alignment(args)