# preprocessing/generate_embeddings/main_generate.py

import argparse
import os
import sys
import numpy as np
import torch 
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# âœ… (æ ¸å¿ƒä¿®æ”¹) å¯¼å…¥å¢å¼ºåçš„ utils.py ä¸­çš„å‡½æ•°
try:
    # æ·»åŠ çˆ¶ç›®å½• (preprocessing/) åˆ° Python è·¯å¾„
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils import (
        load_json, 
        get_id2item_dict, 
        build_text_map, 
        find_first_image_path, 
        load_pil_image, 
        build_output_path, 
        apply_pca_and_save, 
        set_device,
        clean_text # å¦‚æœ encoder æ¨¡å—éœ€è¦
    )
    print("[INFO] æˆåŠŸä»çˆ¶ç›®å½• utils.py å¯¼å…¥å…±äº«å‡½æ•°ã€‚")
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("é”™è¯¯: æ— æ³•ä»çˆ¶ç›®å½• (preprocessing/) å¯¼å…¥ utils.pyã€‚è¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„å’Œ Python è·¯å¾„ã€‚")
    sys.exit(1)

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'generate_embedding'))

# âœ… (æ ¸å¿ƒä¿®æ”¹) ä»å½“å‰ç›®å½•å¯¼å…¥å„ä¸ª encoder æ¨¡å—
try:
    import text_encoder 
    import image_encoder
    import cf_encoder
    import vlm_encoder
    print("[INFO] æˆåŠŸå¯¼å…¥ encoder æ¨¡å—ã€‚")
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("é”™è¯¯: æ— æ³•å¯¼å…¥å½“å‰ç›®å½•ä¸‹çš„ encoder æ¨¡å—ã€‚è¯·ç¡®ä¿ __init__.py æ–‡ä»¶å­˜åœ¨ä¸” encoder æ–‡ä»¶åæ­£ç¡®ã€‚")
    sys.exit(1)

# ğŸš¨ (ç§»é™¤) ä¸å†éœ€è¦ common_utils.py

# =============== æ•°æ®åŠ è½½ (ç°åœ¨ä½¿ç”¨ utils.py å‡½æ•°) ===============
def load_common_data(args):
    """åŠ è½½æ‰€æœ‰ encoder éƒ½éœ€è¦çš„åŸºç¡€æ•°æ® (ä½¿ç”¨å¯¼å…¥çš„ utils å‡½æ•°)"""
    print(f"\n--- åŠ è½½é€šç”¨æ•°æ® ({args.dataset}) ---")
    data_dir = os.path.join(args.save_root, args.dataset) # save_root æŒ‡å‘ ../datasets
    item2id_path = os.path.join(data_dir, f'{args.dataset}.item2id')
    item_meta_path = os.path.join(data_dir, f'{args.dataset}.item.json')
    
    print(f"åŠ è½½ item2id: {item2id_path}")
    id2item = get_id2item_dict(item2id_path) # ä½¿ç”¨ utils.get_id2item_dict
    
    print(f"åŠ è½½ item meta: {item_meta_path}")
    item_meta = load_json(item_meta_path) # ä½¿ç”¨ utils.load_json
    if not item_meta: raise FileNotFoundError(f"item.json æ–‡ä»¶åŠ è½½å¤±è´¥æˆ–ä¸ºç©º: {item_meta_path}")

    images_info = None
    image_dir = None # åˆå§‹åŒ–
    if args.embedding_type in ['image_clip', 'vlm_fused']: 
         # âœ… (ä¿®æ”¹) å›¾åƒè·¯å¾„æ„å»ºæ›´å¥å£®
         # image_root æŒ‡å‘ ../datasets/amazonXX/Images/
         image_base_path = os.path.join(args.image_root, f"amazon{args.data_version}", "Images")
         if not os.path.isdir(image_base_path): # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
              print(f"[WARN] å›¾åƒåŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {image_base_path}ã€‚å¦‚æœæ‚¨ä¸éœ€è¦å›¾åƒï¼Œè¯·å¿½ç•¥ã€‚")
         else:
              images_info_path = os.path.join(image_base_path, f"{args.dataset}_images_info.json")
              image_dir = os.path.join(image_base_path, args.dataset) # å›¾ç‰‡æ–‡ä»¶å¤¹
              print(f"åŠ è½½ image info: {images_info_path}")
              images_info = load_json(images_info_path) or {}
              if not images_info: print(f"[WARN] æœªæ‰¾åˆ°æˆ–åŠ è½½ image info æ–‡ä»¶å¤±è´¥: {images_info_path}")
              if not os.path.isdir(image_dir):
                  print(f"[WARN] å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}ã€‚å°†æ— æ³•åŠ è½½å›¾åƒã€‚")
                  image_dir = None # è®¾ä¸º None
         
    print("é€šç”¨æ•°æ®åŠ è½½å®Œæ¯•ã€‚")
    # è¿”å› image_dir ä»¥ä¾¿åç»­ä½¿ç”¨
    return id2item, item_meta, images_info, image_dir 

# =============== ä¸»ç¨‹åº (è°ƒåº¦é€»è¾‘ä¸å˜ï¼Œè°ƒç”¨å¯¼å…¥çš„å‡½æ•°) ===============
def main():
    parser = argparse.ArgumentParser(description="ç»Ÿä¸€çš„ Embedding ç”Ÿæˆè„šæœ¬")

    # --- æ ¸å¿ƒè°ƒåº¦å‚æ•° ---
    parser.add_argument('--embedding_type', type=str, required=True, 
                        choices=['text_local', 'text_api', 'image_clip', 'cf_sasrec', 'vlm_fused'],
                        help='è¦ç”Ÿæˆçš„ Embedding ç±»å‹')

    # --- æ•°æ®å‚æ•° ---
    parser.add_argument('--dataset', type=str, required=True, help='æ•°æ®é›†åç§°')
    parser.add_argument('--dataset_type', type=str, default='amazon', choices=['amazon', 'movielens'], help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--data_version', type=str, default='14', choices=['14','18'], help='Amazon ç‰ˆæœ¬')
    parser.add_argument('--save_root', type=str, default='../datasets', help='ä¿å­˜é¢„å¤„ç†æ•°æ®çš„æ ¹ç›®å½•')
    # âœ… (ä¿®æ”¹) image_root æŒ‡å‘ amazonXX/Images/ æˆ–ç±»ä¼¼ç›®å½•
    parser.add_argument('--image_root', type=str, default='../datasets', help='åŒ…å«å›¾åƒä¿¡æ¯æ–‡ä»¶å’Œå›¾åƒæ–‡ä»¶å¤¹çš„æ ¹ç›®å½• (e.g., ../datasets)') 

    # --- æ¨¡å‹å‚æ•° ---
    # (ä¿æŒä¸å˜)
    parser.add_argument('--model_name_or_path', type=str, default='sentence-transformers/sentence-t5-base', help='[text_local] æœ¬åœ° Transformer æ¨¡å‹')
    parser.add_argument('--max_sent_len', type=int, default=1024, help='[text_local] æ–‡æœ¬æœ€å¤§é•¿åº¦')
    parser.add_argument('--sent_emb_model', type=str, default='text-embedding-3-large', help='[text_api] OpenAI æ¨¡å‹ ID')
    parser.add_argument('--api_emb_dim', type=int, default=0, help='[text_api] API è¾“å‡ºç»´åº¦ (0 ä¸ºè‡ªåŠ¨)')
    parser.add_argument('--openai_api_key', type=str, default='sk-492a02uVsAauNrYsP4YRW2pvAsELc20hoHJeUh2Sop3GiL3C', help='OpenAI Key')
    parser.add_argument('--openai_base_url', type=str, default='https://yunwu.ai/v1', help='OpenAI Base URL')
    parser.add_argument('--clip_model_name', type=str, default='openai/clip-vit-base-patch32', help='[image_clip] CLIP æ¨¡å‹ ID')
    parser.add_argument('--sasrec_hidden_dim', type=int, default=64, help='[cf_sasrec] éšè—ç»´åº¦')
    parser.add_argument('--sasrec_max_seq_len', type=int, default=50, help='[cf_sasrec] åºåˆ—é•¿åº¦')
    parser.add_argument('--sasrec_n_layers', type=int, default=2, help='[cf_sasrec] å±‚æ•°')
    parser.add_argument('--sasrec_n_heads', type=int, default=2, help='[cf_sasrec] å¤´æ•°')
    parser.add_argument('--sasrec_dropout', type=float, default=0.2, help='[cf_sasrec] Dropout')
    parser.add_argument('--sasrec_epochs', type=int, default=30, help='[cf_sasrec] è®­ç»ƒè½®æ•°')
    parser.add_argument('--sasrec_lr', type=float, default=0.001, help='[cf_sasrec] å­¦ä¹ ç‡')
    parser.add_argument('--sasrec_weight_decay', type=float, default=0.0, help='[cf_sasrec] æƒé‡è¡°å‡')
    parser.add_argument('--vlm_model_name_or_path', type=str, default='Qwen/Qwen3-VL-7B-Instruct', help='[vlm_fused] VLM æ¨¡å‹ ID')
    parser.add_argument('--vlm_prompt_template', type=str, default="Represent this item for recommendation: {}", help='[vlm_fused] Prompt æ¨¡æ¿')

    # --- é€šç”¨ ---
    parser.add_argument('--model_cache_dir', type=str, default=None, help='Hugging Face ç¼“å­˜ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=512, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--pca_dim', type=int, default=512, help='PCA ç›®æ ‡ç»´åº¦ (<=0 ä¸é™ç»´)')
    parser.add_argument('--gpu_id', type=int, default=0, help='GPU ID (<0 ä½¿ç”¨ CPU)')
    
    args = parser.parse_args()
    args.device = set_device(args.gpu_id) # ä½¿ç”¨ utils.set_device

    # --- 1. åŠ è½½é€šç”¨æ•°æ® ---
    try:
        # âœ… (ä¿®æ”¹) æ¥æ”¶ image_dir
        id2item, item_meta, images_info, image_dir = load_common_data(args) 
        text_map = {}
        if args.embedding_type in ['text_local', 'text_api', 'vlm_fused']:
             text_map = build_text_map(args, id2item, item_meta) # ä½¿ç”¨ utils.build_text_map
             if not text_map: print("[WARN] text_map ä¸ºç©ºã€‚")

    except FileNotFoundError as e: print(f"é”™è¯¯ï¼šåŠ è½½åŸºç¡€æ•°æ®å¤±è´¥: {e}"); sys.exit(1)
    except Exception as e: print(f"é”™è¯¯ï¼šåŠ è½½æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"); sys.exit(1)


    # --- 2. è°ƒåº¦ Embedding ç”Ÿæˆ ---
    embeddings = None
    modality_tag = "" 
    model_tag = ""    
    
    print(f"\n--- å¼€å§‹ç”Ÿæˆ Embedding ({args.embedding_type}) ---")

    try:
        if args.embedding_type == 'text_local':
            item_text_list = []
            # ç¡®ä¿æŒ‰æ–° ID é¡ºåºç”Ÿæˆ
            sorted_new_ids = sorted(id2item.keys(), key=int)
            for new_id_str in sorted_new_ids:
                 orig_id = id2item[new_id_str]
                 # encoder éœ€è¦ int ç±»å‹çš„ ID
                 item_text_list.append([int(new_id_str), text_map.get(orig_id, "N/A").split()]) 
                 
            embeddings = text_encoder.generate_local_text(args, item_text_list)
            modality_tag = "text"
            model_tag = args.model_name_or_path

        elif args.embedding_type == 'text_api':
            item_text_list = []
            sorted_new_ids = sorted(id2item.keys(), key=int)
            for new_id_str in sorted_new_ids:
                 orig_id = id2item[new_id_str]
                 item_text_list.append([int(new_id_str), text_map.get(orig_id, "N/A").split()])
                 
            embeddings = text_encoder.generate_api_text(args, item_text_list)
            modality_tag = "text"
            model_tag = args.sent_emb_model

        elif args.embedding_type == 'image_clip':
            if not image_dir: raise ValueError("å›¾åƒç›®å½•æœªæ‰¾åˆ°æˆ–æ— æ•ˆï¼Œæ— æ³•ç”Ÿæˆå›¾åƒåµŒå…¥ã€‚")
            embeddings = image_encoder.generate_clip_image(args, id2item, images_info, image_dir)
            modality_tag = "image"
            model_tag = args.clip_model_name

        elif args.embedding_type == 'cf_sasrec':
            embeddings = cf_encoder.train_and_extract_sasrec(args, len(id2item))
            modality_tag = "cf"
            model_tag = "sasrec"

        elif args.embedding_type == 'vlm_fused':
            if not image_dir: raise ValueError("å›¾åƒç›®å½•æœªæ‰¾åˆ°æˆ–æ— æ•ˆï¼Œæ— æ³•ç”Ÿæˆ VLM èåˆåµŒå…¥ã€‚")
            embeddings = vlm_encoder.generate_vlm_fused(args, id2item, text_map, images_info, image_dir)
            modality_tag = "vlm-fused"
            model_tag = args.vlm_model_name_or_path

        else:
            raise ValueError(f"é”™è¯¯ï¼šæœªçŸ¥çš„ embedding_type: {args.embedding_type}")

    except FileNotFoundError as e: print(f"é”™è¯¯ï¼šç”ŸæˆåµŒå…¥æ—¶ç¼ºå°‘æ–‡ä»¶: {e}"); sys.exit(1)
    except ValueError as e: print(f"é”™è¯¯ï¼šç”ŸæˆåµŒå…¥æ—¶å‚æ•°é”™è¯¯: {e}"); sys.exit(1)
    except Exception as e: print(f"é”™è¯¯ï¼šç”ŸæˆåµŒå…¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"); sys.exit(1)

    # --- 3. éªŒè¯å’Œä¿å­˜ ---
    if embeddings is None or not isinstance(embeddings, np.ndarray) or embeddings.size == 0:
         print(f"é”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ Embeddingï¼")
         sys.exit(1)
         
    if embeddings.shape[0] != len(id2item):
         print(f"é”™è¯¯ï¼šç”Ÿæˆçš„ Embedding æ•°é‡ ({embeddings.shape[0]}) ä¸ item æ•°é‡ ({len(id2item)}) ä¸åŒ¹é…ï¼")
         # å°è¯•ä¿®å¤ï¼ˆå¡«å……æˆ–æˆªæ–­ï¼‰ - è¿™é‡Œé€‰æ‹©æˆªæ–­
         print("å°†å°è¯•æˆªæ–­ Embedding ä»¥åŒ¹é… item æ•°é‡...")
         embeddings = embeddings[:len(id2item)]
         if embeddings.shape[0] != len(id2item): # å¦‚æœæˆªæ–­åä»ä¸åŒ¹é…ï¼ˆä¾‹å¦‚ç”Ÿæˆæ•°é‡ä¸º0ï¼‰
              print("é”™è¯¯ï¼šä¿®å¤åæ•°é‡ä»ä¸åŒ¹é…ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
              sys.exit(1)
              
    # æ„å»ºè¾“å‡ºè·¯å¾„ (ä½¿ç”¨ utils.build_output_path)
    output_path = build_output_path(args, modality_tag, model_tag)
    
    # åº”ç”¨ PCA å¹¶ä¿å­˜ (ä½¿ç”¨ utils.apply_pca_and_save)
    final_output_path = apply_pca_and_save(embeddings, args, output_path)

    if final_output_path: # ç¡®ä¿è·¯å¾„æœ‰æ•ˆ
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼æœ€ç»ˆ Embedding å·²ä¿å­˜è‡³: {final_output_path}")
    else:
        print("\nâŒ ä»»åŠ¡å¤±è´¥ï¼šæœªèƒ½æˆåŠŸä¿å­˜ Embeddingã€‚")

if __name__ == '__main__':
    main()