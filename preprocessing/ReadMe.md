# ğŸ§© UniGenRec æ•°æ®å¤„ç†ä¸Embedding

æœ¬é¡¹ç›®æä¾›ä» **åŸå§‹æ•°æ®ä¸‹è½½ â†’ æ•°æ®é¢„å¤„ç† â†’ æ–‡æœ¬ä¸å›¾åƒ Embedding ç”Ÿæˆ â†’ å¤šæ¨¡æ€èåˆ** çš„ä¸€ç«™å¼å¤„ç†è„šæœ¬ã€‚  
ä»¥ Amazon ä¸ MovieLens ä¸ºä¾‹ã€‚


## ğŸ“¦ 1. ä¸‹è½½æ•°æ®é›†

ä»å…¬å¼€æºä¸‹è½½ Amazon æˆ– MovieLens æ•°æ®é›†ï¼š

```bash
# Amazon æ•°æ®é›†
python download_data.py --source amazon --dataset Sports_and_Outdoors

# MovieLens æ•°æ®é›†
python download_data.py --source movielens --dataset ml-1m
```


## ğŸ–¼ï¸ 2. ä¸‹è½½å›¾ç‰‡èµ„æº

è‹¥æ•°æ®åŒ…å«å›¾åƒå†…å®¹ï¼Œå¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½å¯¹åº”å›¾ç‰‡ï¼š

```bash
# Amazon ç±»æ•°æ®é›†
python download_images.py --dataset_type amazon --dataset Musical_Instruments

# MovieLens æ•°æ®é›†
python download_images.py --dataset_type movielens --dataset ml-1m
```



## ğŸ§¹ 3. æ•°æ®é¢„å¤„ç†

å¯¹åŸå§‹æ•°æ®æ‰§è¡Œæ¸…æ´—ã€æ ¼å¼åŒ–ä¸æ ‡å‡†åŒ–ï¼š

```bash
# Amazon
python process_data.py --dataset_type amazon --dataset Sports_and_Outdoors

# MovieLens
python process_data.py --dataset_type movielens --dataset ml-1m
```

---

## ğŸ”  4. Embedding ç”Ÿæˆ

### ç”Ÿæˆæœ¬åœ° T5 æ–‡æœ¬åµŒå…¥ (PCA åˆ° 512d):

```bash
python process_embedding.py \
    --embedding_type text_local \
    --dataset Baby \
    --model_name_or_path sentence-transformers/sentence-t5-base \
    --pca_dim 512
```

### ç”Ÿæˆ OpenAI API æ–‡æœ¬åµŒå…¥:

```bash
python process_embedding.py \
    --embedding_type text_api \
    --dataset Baby \
    --sent_emb_model text-embedding-3-large \
    --pca_dim 512
```

### ç”Ÿæˆ CLIP å›¾åƒåµŒå…¥:


```bash
python process_embedding.py \
    --embedding_type image_clip \
    --dataset Musical_Instruments \
    --clip_model_name /home/peiyu/PEIYU/LLM_Models/openai-mirror/clip-vit-base-patch32 \
    --pca_dim 512
```

### ç”Ÿæˆ SASRec ååŒåµŒå…¥:

```bash
python process_embedding.py \
    --embedding_type cf_sasrec \
    --dataset Sports_and_Outdoors \
    --sasrec_hidden_dim 64 \
    --sasrec_epochs 100 \
    --pca_dim 0
```

## 5. æ¨¡æ€èåˆ

```bash
python preprocessing/train_fusion_attention.py \
  --dataset Baby \
  --text_model_tag "Qwen/Qwen3-VL-7B-Instruct" \
  --image_model_tag "openai/clip-vit-base-patch32" \
  --fusion_out_dim 512 \
  --epochs 10 \
  --batch_size 1024 \
  --output_tag "sota-attn"
```