# UniGenRec
<p align="center">
  <img src="./asset/logo.png" width="200">
</p>

**UniGenRec** â€” A unified, modular, configuration-driven **Generative Recommendation** toolbox.  
It provides an end-to-end reproducible pipeline covering **Representation â†’ Tokenization â†’ Modeling â†’ Training â†’ Inference**.

ðŸ“˜ arXiv Paper (coming soon)  


# ðŸ”¥ Introduction
Generative Recommendation is rapidly emerging as a new paradigm, shifting from **scoring/matching** â†’ **generative modeling**. However, the current GenRec ecosystem is **highly fragmented**:
- **Representation & Tokenization** are inconsistent (RQ-VAE, VQ-VAE, OPQ, RKMeans, LETTERâ€¦)  
- **Backbones** vary widely (Encoderâ€“Decoder, Decoder-only LLMs, Retrieval-Hybrids)  
- **Training & Inference** pipelines differ significantly (beam search, prefix-tree, guided decoding)

As a result: **models are not comparable, not extensible, and often not reproducible**.

# ðŸŽ¯ Goal

UniGenRec provides a **single, configuration-driven, plug-and-play GenRec stack**, unifying  **Representation â†’ Tokenization â†’ Backbone â†’ Training â†’ Inference** to enable reproducible research and fair comparison across models.

- **A fully unified GenRec stack**
- **Modular and plug-and-play components**
- **Reproducible experiments with config-based control**
- **Fair comparison across GenRec models**
- **First open-source standardization of SID-based modeling**


# ðŸ”§ Pipeline Overview

```
Raw Data
â†“
Download + Preprocessing
â†“
Embedding Generation (Text / Image / CF / VLM)
â†“
Multimodal Fusion (optional)
â†“
Quantization (RQ-VAE / OPQ / PQ / RKMeans)
â†“
Generative Recommender (TIGER / RPG / LETTER / LLMs)
â†“
Inference (Beam Search / Prefix-tree / Contrastive Rerank)
```


---

# ðŸ§± Capability Matrix

| Dimension | Category | Supported Components | Status |
|----------|----------|----------------------|--------|
| **Data** | Datasets | Amazon, MovieLens | âœ“ |
|          | Input Formats | Raw IDs, Embeddings, Codebooks (SID) | âœ“ |
| **Representation** | Text | Qwen, T5, OpenAI Embedding API | âœ“ |
|                   | Vision | CLIP ViT | âœ“ |
|                   | Collaborative | SASRec | âœ“ |
|                   | Fusion | Concat, MLP Fusion | âœ“ |
| **Tokenization / Quantization** | Residual Family | RQ-VAE, Residual KMeans, Residual-VQ | âœ“ |
|                                | Product Family | OPQ, PQ | âœ“ |
|                                | Other | VQ-VAE, Multi-Codebook (RPG-style) | âœ“ |
| **Backbone** | Encoderâ€“Decoder | TIGER-style architectures | âœ“ |
|              | Decoder-only LLM | GPT-2, Qwen, LLaMA | âœ“ |
|              | Retrieval-Hybrid | RPG-style architectures | âœ“ |
| **Training** | Objectives | LM Loss, Contrastive Loss, Hybrid Loss | âœ“ |
|              | Paradigms | SFT, Alignment, Multi-stage Training | âœ“ |
| **Inference** | Decoding | Greedy, Beam Search | âœ“ |
|               | Constraints | Prefix-Tree | âœ“  |




# ðŸš€ Quick Start


**Requirements**
- Python **3.10** (recommended)
- PyTorch, CUDA, and other dependencies will be installed automatically via `requirements.txt`

```bash
git clone https://github.com/yourname/UniGenRec
cd UniGenRec
pip install -r requirements.txt
```
## 1 Data Preprocessing

For dataset downloading, cleaning, formatting, and multimodal data preparation  
(**including text/image extraction, interaction filtering, metadata normalization**),  
please refer to the dedicated guide:

ðŸ‘‰ **See detailed tutorial:**  
[GenRec-Factory Data Processing & Embedding Guide](./preprocessing/ReadMe.md)

This includes:

## 2 Quantization

```bash
cd quantization

python main.py \
  --model_name rqvae \
  --dataset_name Musical_Instruments \
  --embedding_modality text \
  --embedding_model text-embedding-3-large
```

## 3 Generative Recommendation Models

```bash
python main.py \
  --model TIGER \
  --dataset Baby \
  --quant_method rqvae
```
