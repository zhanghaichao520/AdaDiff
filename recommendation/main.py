# main.py

import argparse
import logging
import torch
import torch.optim as optim
import os
import pprint

from dataset import GenRecDataset
from dataloader import GenRecDataLoader
from trainer import train_one_epoch, evaluate
from utils import load_and_process_config, setup_logging, set_seed, get_model_class


def main():
    # 1) å‚æ•°ï¼šç°åœ¨åªéœ€è¦æ¨¡å‹ã€æ•°æ®é›†å’Œé‡åŒ–æ–¹æ³•
    parser = argparse.ArgumentParser(description="GenRec Universal Training Pipeline")
    parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹åç§° (e.g., TIGER)')
    parser.add_argument('--dataset', type=str, required=True, help='æ•°æ®é›†åç§° (e.g., Beauty)')
    parser.add_argument('--quant_method', type=str, required=True, choices=['rkmeans', 'rvq', 'rqvae', 'opq', 'pq'],
                        help='é‡åŒ–æ–¹æ³• (rkmeans / rvq / rqvae)')
    args = parser.parse_args()

    # 2) åŠ è½½å¹¶å¤„ç†æ‰€æœ‰é…ç½®
    config = load_and_process_config(args.model, args.dataset, args.quant_method)

    # 3) åˆå§‹åŒ–
    setup_logging(config['log_path'])
    set_seed(config['training_params']['seed'])
    logging.info(f"Configuration loaded for {args.model} on {args.dataset} with {args.quant_method}.")

    logging.info("=" * 50)
    logging.info("--- Final Configuration ---")
    # ä½¿ç”¨ pprint.pformat å°‡å­—å…¸æ ¼å¼åŒ–ç‚ºä¸€å€‹æ˜“è®€çš„å­—ä¸²
    config_str = pprint.pformat(config)
    logging.info("\n" + config_str)
    logging.info("=" * 50)

    # 4) è®¾å¤‡
    device = torch.device(config['training_params']['device'] if torch.cuda.is_available() else 'cpu')
    logging.info(f"Using device: {device}")
    num_workers = config['training_params'].get('num_workers', 4)

    # 6) æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    # 6) âœ¨ æ¨¡å‹èˆ‡å„ªåŒ–å™¨ (å‹•æ…‹è¼‰å…¥) âœ¨
    logging.info(f"Dynamically loading model: {args.model}")
    # é€éè¼”åŠ©å‡½æ•¸ï¼Œç”¨å­—ä¸²ç²å–æ¨¡å‹ Class
    ModelClass = get_model_class(args.model)
    # å¯¦ä¾‹åŒ–æ¨¡å‹
    model = ModelClass(config)
    
    # èª¿æ•´è©åµŒå…¥å±¤å¤§å° (ä½¿ç”¨ self.t5)
    model.to(device)

        # 5) æ•°æ®é›†ï¼ˆç›´æ¥ç”¨ utils é‡Œè‡ªåŠ¨æ‹¼å¥½çš„ jsonl è·¯å¾„ï¼‰
    train_dataset = GenRecDataset(
        dataset_path=config['train_json'],
        code_path=config['code_path'], mode='train', max_len=config['model_params']['max_len'],
        vocab_sizes=config['vocab_sizes'], bases=config['bases']
    )
    validation_dataset = GenRecDataset(
        dataset_path=config['valid_json'],
        code_path=config['code_path'], mode='evaluation', max_len=config['model_params']['max_len'],
        vocab_sizes=config['vocab_sizes'], bases=config['bases']
    )
    test_dataset = GenRecDataset(
        dataset_path=config['test_json'],
        code_path=config['code_path'], mode='evaluation', max_len=config['model_params']['max_len'],
        vocab_sizes=config['vocab_sizes'], bases=config['bases']
    )
    train_loader = GenRecDataLoader(train_dataset, model=model, batch_size=config['training_params']['batch_size'], shuffle=True, num_workers=num_workers)
    validation_loader = GenRecDataLoader(validation_dataset, model=model, batch_size=config['evaluation_params']['batch_size'], shuffle=False, num_workers=num_workers)
    test_loader = GenRecDataLoader(test_dataset, model=model, batch_size=config['evaluation_params']['batch_size'], shuffle=False, num_workers=num_workers)

    
    # âœ¨ 3. æ–°å¢å€å¡Šï¼šæ‰“å°æ¨¡å‹åƒæ•¸æ•¸é‡å’Œè©³ç´°æ¶æ§‹ âœ¨
    logging.info("=" * 50)
    logging.info("--- Model Details ---")
    logging.info(model.n_parameters) # æ‰“å°åƒæ•¸æ•¸é‡
    logging.info("--- Model Architecture ---")
    logging.info(model) # æ‰“å°æ¨¡å‹æ¶æ§‹
    logging.info("=" * 50)

    optimizer = optim.Adam(model.parameters(), lr=config['training_params']['lr'])


    # 7) è¨“ç·´-è©•ä¼°å¾ªç’°
    best_ndcg = 0.0
    early_stop_counter = 0
    best_epoch = 0
    best_val_results = None
    best_test_results = None

    for epoch in range(config['training_params']['num_epochs']):
        logging.info(f"--- Epoch {epoch + 1}/{config['training_params']['num_epochs']} ---")
        train_loss = train_one_epoch(model, train_loader, optimizer, device)
        logging.info(f"Training loss: {train_loss:.4f}")

        # âœ¨ æ”¹åŠ¨ 1: evaluate ç°åœ¨è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„å­—å…¸ âœ¨
        val_results = evaluate(
            model, 
            validation_loader, 
            config['evaluation_params']['topk_list'], 
            device
        )
        # ç»Ÿä¸€æ‰“å°æ‰€æœ‰éªŒè¯é›†ç»“æœ
        logging.info(f"Validation Results: {val_results}")

        # âœ¨ æ”¹åŠ¨ 2: ä»ç»“æœå­—å…¸ä¸­è·å– NDCG@20 âœ¨
        current_ndcg = val_results.get('NDCG@20', 0.0)
        
        if current_ndcg > best_ndcg:
            best_ndcg = current_ndcg
            early_stop_counter = 0
            logging.info(f"ğŸš€ New best NDCG@20 on validation: {best_ndcg:.4f}")

            # âœ¨ æ”¹åŠ¨ 3: å¯¹æµ‹è¯•é›†ä¹ŸåŒæ ·å¤„ç† âœ¨
            test_results = evaluate(
                model, 
                test_loader, 
                config['evaluation_params']['topk_list'], 
                device
            )
            logging.info(f"Test Results: {test_results}")

            # æ›´æ–°æœ€ä½³ç»“æœ
            best_epoch = epoch + 1
            best_val_results = val_results
            best_test_results = test_results

            torch.save(model.state_dict(), config['save_path'])
            logging.info(f"Best model saved to {config['save_path']}")
        else:
            early_stop_counter += 1
            logging.info(f"No improvement in NDCG@20. Early stop counter: {early_stop_counter}/{config['training_params']['early_stop']}")
            if early_stop_counter >= config['training_params']['early_stop']:
                logging.info("Early stopping triggered.")
                break
    
    # âœ¨ æ”¹åŠ¨ 4: æ›´æ–°æœ€ç»ˆçš„æ‰“å°é€»è¾‘ âœ¨
    logging.info("="*50)
    logging.info("ğŸ Training Finished!")
    if best_test_results:
        logging.info(f"ğŸ† Best performance found at Epoch {best_epoch}")
        logging.info(f"  - Best Validation Results: {best_val_results}")
        logging.info(f"  - Corresponding Test Results: {best_test_results}")
        logging.info(f"  - Best model checkpoint saved at: {config['save_path']}")
    else:
        logging.info("No improvement was observed during training. No model was saved.")
    logging.info("="*50)
    # ---------------------------------------


if __name__ == "__main__":
    main()
