# 文件路径: configs/instruction_base.yaml

# 基础路径设置
paths:
  # 数据集根目录模板 (数据集名称会被填充)
  dataset_root: "../datasets/{dataset_name}"
  # 输出根目录模板 (数据集和模型别名会被填充)
  output_root: "../outputs/instruction_tuning/{dataset_name}/{base_model_alias}"
  # Hugging Face 模型缓存目录 (可选)
  model_cache_dir: null # null 表示使用默认缓存

# 模型别名到实际路径/Hub ID 的映射
# 你可以在这里添加更多模型
models:
  gpt2: "gpt2"
  gpt2-medium: "gpt2-medium"
  llama2-7b: "/path/to/your/local/llama-7b" # 或者 HuggingFace Hub ID
  # 添加你自己的模型别名和路径...

# Tokenizer 和序列长度设置
token_params:
  # 默认最大序列长度
  max_seq_len: 512
  # 指定 tokenizer 路径 (如果与模型路径不同，否则设为 null)
  tokenizer_path: null

# PEFT (LoRA) 默认参数
peft_params:
  lora_r: 8
  lora_alpha: 32
  lora_dropout: 0.1
  # target_modules: ["q_proj", "v_proj"] # 可以取消注释并指定

# 训练默认参数
training_params:
  epochs: 3
  batch_size: 4
  eval_batch_size: 8
  lr: 0.0003 # 3e-4
  warmup_ratio: 0.1
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  # 早停设置 (可选)
  # early_stopping_patience: 3

# 设备设置
device: "cuda:0" # 默认 GPU ID 或 "cpu"