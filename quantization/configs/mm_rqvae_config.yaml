# filename: configs/mm_rqvae_config.yaml

common:
  device: 'cuda:0'       # 训练和评估使用的设备 ('cuda:0', 'cpu', etc.)
  eval_interval: 50      # 每隔多少个 epoch 进行一次评估 (如果适用)

# --- MM-RQVAE (Multi-Modal RQVAE) 配置 ---
mm_rqvae: # <-- 关键：顶层键与模型名称匹配

  # --- 模型架构参数 ---
  model_params:
    # 编码器/解码器 MLP 结构 (每个模态独立，但结构相同)
    # 输入维度 (input_size_text/image) 将从加载的数据动态获取，无需在此指定
    hidden_sizes: [512, 256] # 输入 -> 512 -> 256 -> latent
    latent_size: 128         # 融合后的潜在空间维度 (也是量化器的输入/输出维度)
    
    # 共享量化器 (RQBottleneck) 参数
    num_levels: 3            # 量化层数 (码本深度)
    codebook_size: 256       # 每层码本的大小 (词汇量 K)
    
    dropout: 0.1             # MLP 中的 Dropout 比率

  # --- 训练过程参数 ---
  training_params:
    # 重建损失权重 (新增，用于平衡文本和图像的重要性)
    w_recon_T: 1.0           # 文本重建损失的权重 (可以设高一些，如果文本是黄金标准)
    w_recon_I: 0.5           # 图像重建损失的权重 (可以设低一些，如果图像质量不高)
    
    # 量化损失权重 (对应代码中的 self.latent_loss_weight)
    latent_loss_weight: 0.25 # VQ commitment loss / quant_loss 的权重
    
    # 重建损失类型 (对应代码中的 self.loss_type)
    loss_type: 'mse'        # 重建损失类型 ('mse' 或 'l1')

    # 标准训练参数 (与原 RQVAE 保持一致或根据需要调整)
    batch_size: 1024         # 训练批次大小
    epochs: 1000             # 总训练轮数
    lr: 0.001                # 学习率
    weight_decay: 0.0        # 权重衰减
    optimizer: "AdamW"       # 优化器类型